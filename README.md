# Walmart
1.Given a 20GB file,how will you design your dataproc/spark cluster(workers,memory,cores etc.,)..?
2.What table/file formats have you worked with in your work experience..?
3.Advantage of Delta Format over Parquet..?
4.How would you replicate DeltaMerge behaviour if your target table is in parquet format..?
5.What is Z-order clustering..?
6.What is the difference between static vs dynamic partition pruning..?
7.What spark optimization techniques have you used in your work expereince..?
8.Difference between cache() vs persistence in spark..?
9.Difference between git fetch vs git pull..?
10.How would you deduplicate rows with Y/N flag preference..?
11.Why can't we use RANK(),DENSE_RANK() instead of ROW_NUMBER() based on a given use case..?
12.What does dropDuplicates() does in pyspark..?
13.Given item+flag data:how would you group and retain proper flags and remove duplicates..?
14.What does show(truncate=False) do vs default show() in spark..?
15.How to drop duplicates using ROW_NUMBER()..?
16.Get item with maximum sales per day using window functions..?
17.How to convert daily level dates into continuous start/end date ranges..?
